version: "3.9"

# Docker Compose stack dedicated to the search subsystem. The file keeps the
# services isolated from the default development environment so contributors can
# opt-in only when working on the search pipeline.
services:
  searxng:
    image: searxng/searxng:latest
    container_name: mcp-searxng
    restart: unless-stopped
    ports:
      - "127.0.0.1:8080:8080"
    volumes:
      - ./searxng/settings.yml:/etc/searxng/settings.yml:ro
    healthcheck:
      # SearxNG images do not ship curl, so rely on Python's stdlib to probe the
      # health endpoint and fall back to the home page if /healthz is
      # unavailable. Any non-successful responses trigger a retry.
      test:
        - CMD-SHELL
        - |
          python3 - <<'PYTHON'
          import sys
          import urllib.error
          import urllib.request

          BASE_URL = "http://localhost:8080"
          PATHS = ("/healthz", "/")

          def main() -> int:
              for path in PATHS:
                  try:
                      with urllib.request.urlopen(f"{BASE_URL}{path}", timeout=5) as resp:
                          status = getattr(resp, "status", 200)
                          if status < 400:
                              return 0
                  except urllib.error.URLError:
                      continue
                  except Exception:
                      continue
              return 1

          sys.exit(main())
          PYTHON
      interval: 10s
      timeout: 5s
      retries: 6
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1024M
    networks:
      - search_net

  unstructured:
    image: quay.io/unstructured-io/unstructured-api:latest
    container_name: mcp-unstructured
    restart: unless-stopped
    ports:
      - "127.0.0.1:8000:8000"
    healthcheck:
      # The unstructured API image also lacks curl, so rely on Python to POST a
      # lightweight ping payload to the general extraction endpoint.
      test:
        - CMD-SHELL
        - |
          python3 - <<'PYTHON'
          import json
          import sys
          import urllib.error
          import urllib.request

          REQUEST = urllib.request.Request(
              "http://localhost:8000/general/v0/general",
              data=json.dumps({"text": "ping"}).encode(),
              headers={"Content-Type": "application/json"},
          )

          try:
              urllib.request.urlopen(REQUEST, timeout=10)
              sys.exit(0)
          except urllib.error.URLError:
              sys.exit(1)
          except Exception:
              sys.exit(1)
          PYTHON
      interval: 15s
      timeout: 10s
      retries: 6
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1536M
    networks:
      - search_net

  server:
    container_name: mcp-search-server
    build:
      context: ..
      dockerfile: Dockerfile
    restart: unless-stopped
    depends_on:
      searxng:
        condition: service_healthy
      unstructured:
        condition: service_healthy
    environment:
      START_HTTP: "1"
      MCP_HTTP_HOST: 0.0.0.0
      MCP_HTTP_PORT: "8765"
      MCP_HTTP_PATH: /mcp
      MCP_HTTP_ALLOW_NOAUTH: "1"
      SEARCH_SEARX_BASE_URL: http://searxng:8080
      SEARCH_SEARX_API_PATH: /search
      SEARCH_SEARX_TIMEOUT_MS: "15000"
      SEARCH_SEARX_ENGINES: bing,ddg,wikipedia,arxiv,github
      SEARCH_SEARX_CATEGORIES: general,news,images,files
      SEARCH_FETCH_TIMEOUT_MS: "20000"
      SEARCH_FETCH_MAX_BYTES: "15000000"
      SEARCH_FETCH_UA: CodexSearchBot/1.0
      UNSTRUCTURED_BASE_URL: http://unstructured:8000
      UNSTRUCTURED_TIMEOUT_MS: "30000"
      UNSTRUCTURED_STRATEGY: hi_res
      SEARCH_INJECT_GRAPH: "1"
      SEARCH_INJECT_VECTOR: "1"
    ports:
      - "127.0.0.1:8765:8765"
    networks:
      - search_net

networks:
  search_net:
    driver: bridge
