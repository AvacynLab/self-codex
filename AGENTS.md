## üéØ Brief (lis-moi d‚Äôabord)

**Objectifs attendus**

1. Renforcer la **robustesse** du moteur Search (SearxNG ‚Üí fetch ‚Üí unstructured ‚Üí normalisation ‚Üí KG/Vector), r√©duire la dette (URLs canonis√©es, sniff MIME, conditional GET, NFC), consolider les **erreurs typ√©es** et la **t√©l√©m√©trie**.
2. **Unifier la journalisation**: n‚Äôavoir **qu‚Äôun seul** dossier de validation (`validation_run` **ou** `validation_runs`) et y consigner **100%** des artefacts d‚Äôex√©cutions.
3. Garder l‚Äô**infra SearxNG** self-host et Unstructured op√©rationnelles, sans r√©gression.
4. **Tests** solides (unit/int/E2E) et **build** strict (TS strict, `exactOptionalPropertyTypes`, Node ‚â• 20), **z√©ro `undefined`** dans les JSON publics.

---

## üß± Contraintes build & tests (√† respecter partout)

* **Node ‚â• 20** obligatoire (ESM, `fetch` natif, `AbortController`).
* **TypeScript strict** + `exactOptionalPropertyTypes: true`. Tous les retours JSON publics **omettent** les cl√©s absentes (ne jamais renvoyer `undefined`).
* **Erreurs typ√©es** : `{ code: string; message: string; details?: unknown }`.
* **Logs** via logger structur√© (pas de `console.*`) avec **redaction** des secrets.
* **Budgets/Timeouts** outill√©s dans les Tools MCP ; **idempotence** (cl√© de requ√™te stable).
* **Tests** : mocks r√©seaux (`nock`), **sans sleeps**, fake timers si n√©cessaire ; snapshots **stabilis√©s** (strip des timestamps/`fetchedAt`/`tookMs`).
* **Couverture**: ‚â• **90%** sur `src/search/**`, ‚â• **85%** global.

---

## A) Infrastructure SearxNG & Unstructured (v√©rif + petites retouches)

* [x] `docker/docker-compose.search.yml`

  * [x] V√©rifier que les services `searxng`, `unstructured`, `server` ont des **healthchecks** stables (timeout raisonnables, retries).
  * [x] Confirmer le **r√©seau priv√©** `search_net` et les **limites CPU/RAM** en CI.
  * [x] (Si absent) commenter **clairement** l‚Äôusage ou non du `result_proxy`.

* [x] `docker/searxng/settings.yml`

  * [x] Repasser sur la **liste d‚Äôengines** activ√©s (retirer ceux non pertinents/licences douteuses).
  * [x] S‚Äôassurer que **categories** incluent au minimum `general,news,images,files`.
  * [x] Documenter `safe_search` (0 en dev, 1 en prod si besoin).

* [x] `env/.env.example`

  * [x] V√©rifier la pr√©sence et les defaults de :

    * [x] `SEARCH_SEARX_BASE_URL`, `SEARCH_SEARX_API_PATH=/search`, `SEARCH_SEARX_TIMEOUT_MS`
    * [x] `SEARCH_SEARX_ENGINES`, `SEARCH_SEARX_CATEGORIES`
    * [x] `UNSTRUCTURED_BASE_URL`, `UNSTRUCTURED_TIMEOUT_MS`, `UNSTRUCTURED_STRATEGY`
    * [x] `SEARCH_FETCH_TIMEOUT_MS`, `SEARCH_FETCH_MAX_BYTES`, `SEARCH_FETCH_UA`
    * [x] `SEARCH_INJECT_GRAPH`, `SEARCH_INJECT_VECTOR`
    * [x] `SEARCH_FETCH_RESPECT_ROBOTS` (mettre **true** en prod recommand√©e)
    * [x] `SEARCH_PARALLEL_FETCH`, `SEARCH_PARALLEL_EXTRACT`, `SEARCH_MAX_RESULTS`

---

## B) Normalisation et t√©l√©chargement ‚Äî **noyau Search** (fichier par fichier)

### `src/search/searxClient.ts`

* [x] **Canonicalisation d‚ÄôURL (NOUVEAU)**

  * [x] Avant toute d√©duplication :

    * [x] retirer `#fragment`.
    * [x] supprimer les param√®tres **tracking** (`utm_*`, `ref`, `fbclid`, etc.).
    * [x] **trier** alphab√©tiquement les query params restants.
  * [x] Mapper au client les champs **h√©t√©rog√®nes** ‚Üí `publishedAt`, `mime` (faire la **conversion ici**).
* [x] **Retry s√©lectif + backoff**

  * [x] Retries sur `429/502/503/504` uniquement, **pas** sur `4xx` classiques.
  * [x] **Jitter** dans le backoff.
* [x] **Timeout** via `AbortController` (d√©j√† en place) ‚Üí v√©rifier les chemins d‚Äôerreur.
* [x] **Tests**

  * [x] Ajouter des cas sur **canonicalisation** (`utm_*`, fragments, ordre des params).
  * [x] Tests retries (1‚Äì2 tentatives) et abort.

### `src/search/downloader.ts`

* [x] **Streaming + coupe dure** (d√©j√† pr√©sent) ‚Üí **ajouter** un **sniff MIME par signature** :

  * [x] PDF `%PDF-`, JPEG `\xFF\xD8`, PNG `\x89PNG`, ZIP `PK\x03\x04` (au minimum).
  * [x] Utiliser ce sniff uniquement si `content-type` **absent/incoh√©rent**.
* [x] **Conditional GET (NOUVEAU)**

  * [x] Si `ETag` ou `Last-Modified` connus pour l‚ÄôURL : envoyer `If-None-Match` / `If-Modified-Since`.
  * [x] Si 304 : retourner proprement un objet `RawFetched` **annot√©** (`notModified: true`) et **√©viter** de repasser l‚Äôextraction.
* [x] **DocId stable**

  * [x] Fallback si pas d‚Äô`ETag`/`LM` : hash `(url + premier 1KB de contenu)` pour stabiliser.
* [x] **Tests**

  * [x] Cas **MIME trompeur** : header `text/html` mais PDF r√©el ‚Üí sniff d√©tecte PDF.
  * [x] Cas **304** : ETag/LM produisent un non-t√©l√©chargement, pipeline respecte `notModified`.

### `src/search/extractor.ts`

* [x] **Chemin unique** d‚Äôappel Unstructured (d√©j√† OK) ‚Üí **passer la langue d√©tect√©e comme hint** quand dispo.
* [x] **Cap de pages PDF** (NOUVEAU)

  * [x] Si `contentType=application/pdf` et doc volumineux ‚Üí extraire **max N pages** (ex. 40) et poser `metadata.truncated=true`.
* [x] **Tests**

  * [x] Cas PDF long : assert `truncated=true`.
  * [x] Mapping segments complet (title/list/table/figure/caption/code).

### `src/search/normalizer.ts`

* [x] **Unicode NFC (NOUVEAU)**

  * [x] `text = text.normalize('NFC').replace(/\s+/g,' ').trim()` **avant** hash & d√©dup.
* [x] **D√©dup par hash**

  * [x] Cl√© = `kind + '|' + hash(text_normalized)` (pas de cl√©s immenses en RAM).
* [x] **Titre fallback**

  * [x] Si `doc.title` vide, utiliser **le 1er segment `kind='title'`**.
* [x] **Tests**

  * [x] Cas accents combin√©s (NFD) vs NFC ‚Üí doivent d√©dupliquer.
  * [x] Cas titres absents ‚Üí fallback depuis segment.

---

## C) Ingestion KG / Vector

### `src/search/ingest/toKnowledgeGraph.ts`

* [x] **D√©bouncer local** (Set) sur `(s,p,o)` avant `upsertTriple`.
* [x] **Mentions**

  * [x] Stoplist FR/EN **r√©utilisable** dans le fichier, `minLength‚â•3`, `minFreq‚â•2`.
* [x] **Tests**

  * [x] Triples **non dupliqu√©s** dans une m√™me run.
  * [x] Mentions filtr√©es (peu de bruit).

### `src/search/ingest/toVectorStore.ts`

* [x] **Chunking ‚Äútitre + paragraphe‚Äù (NOUVEAU)**

  * [x] Si un `title` < 10 tokens est imm√©diatement suivi d‚Äôun `paragraph`, **fusionner** (chunk plus informatif).
* [x] **Skip des doublons successifs** (hash des chunks).
* [x] **Metadata** : `language` forc√©e en **lower-case**.
* [x] **Tests**

  * [x] V√©rifier fusion titre+para.
  * [x] V√©rifier skip chunk dupliqu√© N/N+1.
  * [x] V√©rifier `metadata.language` en lower-case.

---

## D) Orchestration, Events & T√©l√©m√©trie

### `src/search/pipeline.ts`

* [x] **Concurrence contr√¥l√©e**

  * [x] Utiliser le **semaphore/p-limit existant** pour `fetch` et `extract` (√©viter les bursts).
* [x] **Taxonomie des erreurs** (stabiliser)

  * [x] `network_error | robots_denied | max_size_exceeded | extract_error | ingest_error`.
* [x] **jobId**

  * [x] G√©n√©rer `jobId = hash(arguments)` ; **inclure** dans `search:*` events et r√©sultats Tools.
* [x] **Events l√©gers**

  * [x] Ne pas embarquer de payload volumineux (segments) dans `eventStore.emit`.
* [x] **Tests**

  * [x] `allSettled` sur batchs ; erreurs class√©es ; `jobId` propag√© ; √©v√©nements ordonn√©s.

### `src/search/metrics.ts`

* [x] **Labels stables**

  * [x] `{ step, contentType, domain }` (**jamais l‚ÄôURL**).
* [x] **Buckets** log-√©chelle (50ms ‚Üí 20s).
* [x] **Tests**

  * [x] V√©rifier l‚Äôenregistrement de chaque √©tape (searx/fetch/extract/ingest*).

---

## E) Tools MCP & Registry

### `src/tools/search_run.ts`

* [x] **Sch√©ma strict**

  * [x] zod `.strict()` + defaults (`maxResults.default(6)`).
* [x] **Sortie stable**

  * [x] `{ ok:true, jobId, count, docs, warnings? }` ‚Üí `warnings` **omis** si vide.
  * [x] **Propager** `budgetUsed` si dispo, sans d√©passer `bytesOut`.
* [x] **Tests**

  * [x] Snapshot **apr√®s strip** des champs volatils.

### `src/tools/search_index.ts`

* [x] **Normaliser l‚Äôinput**

  * [x] `url` string **‚Üí** `urls: string[]`.
* [x] **Partials**

  * [x] Retour `{ ok:true, docs, errors? }` (omets si vide).
* [x] **Tests**

  * [x] Cas multi-URL, plus une qui √©choue ‚Üí `errors` pr√©sent, `docs` partiels.

### `src/tools/search_status.ts`

* [x] **Not implemented typ√©**

  * [x] `{ ok:false, code:'not_implemented', message:'...' }`.
* [x] **Tests**

  * [x] Snapshot stable.

### `src/mcp/registry.ts` (ou le routeur central si ailleurs)

* [x] **Tags & budgets**

  * [x] `tags: ['search','web','ingest','rag']`.
  * [x] √âlargir `timeMs` (ex. 90s) si gros PDFs.
* [x] **Help concis**

  * [x] Un **exemple JSON** **monoligne** par tool.

---

## F) EventStore & Dashboard

### `src/eventStore.ts`

* [x] **Versionner** `payload` des `search:*` : `payload.version = 1`.
* [x] **Tronquer** `error.message` > 1000 chars.
* [x] **S√©rialisation stable** (ordre des cl√©s si ton diff tooling le requiert).
* [x] **Tests**

  * [x] V√©rifier redaction et taille max.

### `src/monitor/dashboard.ts`

* [x] **Debounce SSE** 250‚Äì500ms si rafales.
* [x] **Cap Top domaines** (ex. top 20).
* [x] *(Optionnel)* endpoint `/api/search/summary` JSON si besoin scripting.
* [x] **Tests**

  * [x] Rend correctement avec un grand nombre d‚Äô√©v√©nements.

---

## G) Knowledge & Memory

### `src/knowledge/knowledgeGraph.ts`

* [x] **Idempotence locale** lors d‚Äôun m√™me run (Set) pour `(s,p,o)`.
* [x] **Provenance** : √©viter les duplications identiques sur `withProvenance`.
* [x] **Tests**

  * [x] Triple identique dans une m√™me transaction ‚Üí 1 seule √©criture.

### `src/memory/vector.ts`

* [x] **Cap par doc** (si d√©j√† pr√©sent, s‚Äôassurer qu‚Äôil s‚Äôapplique aux runs Search).
* [x] **Metadata** : verifier `docId` non vide, langue lower-case.
* [x] **Tests**

  * [x] Respect du cap ; recherche par similarit√© fonctionne.

---

## H) Scripts & ex√©cution

### `scripts/setup-environment.mjs` (ou `scripts/setup-agent-env.sh`)

* [x] **Fail fast Node ‚â• 20** (arr√™ter si version trop basse).
* [x] **Warn** si `SEARCH_SEARX_BASE_URL` ou `UNSTRUCTURED_BASE_URL` **absents**.
* [x] **Dossiers runtime** : cr√©er `./validation_run` (ou variante retenue) + `./children`.
* [x] **Pointer les logs** par d√©faut sur `./validation_run/logs/self-codex.log`.
* [x] **Supprimer** toute r√©f√©rence obsol√®te √† `START_MCP_BG` si r√©ellement non utilis√©e (sinon documenter). *(Toujours utilis√©e pour l'orchestration en arri√®re-plan ‚Äî documentation ajout√©e dans `docs/validation-run-runtime.md`.)*

### `scripts/run-search-e2e.ts` / `scripts/run-search-smoke.ts` / `scripts/validate-run.mjs`

* [x] Remplacer **toute √©criture** vers des chemins historiques (`runs/‚Ä¶`) par le **dossier de validation retenu** (voir section I).
* [x] Cr√©er syst√©matiquement `input.json`, `response.json`, `events.ndjson`, `timings.json`, `errors.json`, `kg_changes.ndjson`, `vector_upserts.json`, `server.log` dans **chaque sc√©nario**.
* [x] **Tests**: adapter les assertions de chemins.

---

## I) **Unification du dossier de validation** (IMPORTANT)

* [x] **Choisir** la convention finale :

  * [x] **Option A** : `validation_run/` (singulier)
  * [ ] **Option B** : `validation_runs/` (pluriel) *(n/a apr√®s migration)*
    ‚Üí **Choisis une seule et unique** option.

* [x] **Supprimer le doublon**

  * [x] Si tu gardes `validation_run/` :

    * [x] **D√©placer/merger** tout le contenu utile de `validation_runs/` vers `validation_run/`.
    * [x] **Supprimer** le dossier `validation_runs/`.
  * [ ] Si tu gardes `validation_runs/` :

    * [ ] **D√©placer/merger** `validation_run/` ‚Üí `validation_runs/`.
    * [ ] **Supprimer** `validation_run/`.

* [ ] **Rendre coh√©rents** tous les pointeurs

  * [x] Mettre √† jour `MCP_RUNS_ROOT` dans `.env.example` et dans les **scripts** pour viser **le dossier retenu**.
  * [x] Rechercher/remplacer dans le code/tests/doc : r√©f√©rences √† l‚Äôancien nom (aucune occurrence restante en dehors de cette t√¢che).
  * [x] **V√©rifier** en E2E qu‚Äô**100%** des artefacts sont produits dans le dossier conserv√©.

* [x] **Tests**

  * [x] Mettre √† jour les tests qui valident la pr√©sence des fichiers de run (chemins).
  * [x] Ajouter un test de **non-existence** de l‚Äôancien dossier apr√®s la migration.

---

## J) Tests suppl√©mentaires / durcissement

* [x] **Unitaires**

  * [x] searxClient : propri√©t√© **canonicalisation** (jeu de param√®tres g√©n√©r√©s), retries, abort.
  * [x] downloader : sniff signatures, conditional GET (304), clamp taille.
  * [x] extractor : `truncated=true` sur PDF gros, mapping complet.
  * [x] normalizer : NFC, d√©dup hash, fallback titre.
  * [x] ingest KG/Vector : debounce triples, fusion titre+para, skip chunk dupliqu√©.
  * [x] pipeline : error kinds, jobId, events l√©gers, `allSettled`.

* [x] **Int√©gration**

  * [x] `search.run` avec mocks r√©seaux : v√©rifier docs ing√©r√©s, erreurs **class√©es**, `jobId` dans la r√©ponse.

* [x] **E2E**

  * [x] Compose up, ex√©cuter au moins S01 / S05 / S06, v√©rifier **idempotence**, **robots/size**, et **artefacts** sous le **dossier de validation choisi**.

* [x] **Couverture**

  * [x] V√©rifier ‚â•90% sur `src/search/**`, ‚â•85% global.
  * [x] Stabiliser les snapshots (strip des champs volatils).

---

## K) Documentation & Changelog

* [x] `docs/search-module.md`

  * [x] Ajouter un **encadr√©** sur la canonicalisation d‚ÄôURL, le sniff MIME et le conditional GET.
  * [x] Pr√©ciser la **convention retenue** du dossier de validation et les **fichiers attendus**.

* [x] `CHANGELOG.md`

  * [x] Entr√©e `improvement: search robustness (URL canonicalization, MIME sniff, conditional GET, NFC); validation folder unified`.

---

## ‚úÖ Crit√®res d‚Äôacceptation (avant close)

* [x] Build **OK** (Node ‚â• 20, TS strict, aucun warning notable).
* [x] `search.run` (S01) : ‚â• 1 doc ing√©r√©, embeddings pr√©sents, events `search:*`, artefacts complets dans le **dossier de validation retenu**.
* [x] S05 (replay) : **z√©ro duplication** (m√™mes `docId`).
* [x] S06 (robots/size) : erreurs **class√©es** et non bloquantes.
* [x] Dashboard : m√©triques par √©tape (searx/fetch/extract/ingest*) coh√©rentes, labels stables.
* [x] **Un seul** dossier de validation dans le repo (l‚Äôautre **supprim√©**), tous scripts & tests **pointent** dessus.
* [x] Couverture atteinte (‚â•90% `src/search/**`, ‚â•85% global).

---

Si tu veux, je peux ensuite te fournir un **patch group√©** (diff par fichier) appliquant exactement ces changements, et un **script unique** qui ex√©cute S01‚ÜíS10 et consolide `summary.json` dans **le** dossier de validation retenu.

---

### Historique

- 2025-10-31 : ‚úÖ Downloader sniff MIME + conditional GET (304 annot√©) + commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/downloader.test.ts`.
- 2025-10-31 : ‚úÖ README.md et docs/mcp-http-troubleshooting.md align√©s sur la convention `validation_run/` (suppression des r√©f√©rences `runs/`).
- 2025-10-31 : ‚úÖ `npm run test -- tests/validation-runs.response-summary.test.ts` ex√©cut√© (build + typecheck + suite compl√®te).
- 2025-10-31 : ‚úÖ Tests unitaires `searxClient` √©tendus (canonicalisation, non-retry 4xx, timeout abort) + commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/searxClient.test.ts`.
- 2025-10-31 : ‚úÖ Pipeline `jobId` hach√© + taxonomie d'erreurs stabilis√©e + fa√ßades `search.run`/`search.index` retournant le nouvel identifiant ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/pipeline.test.ts tests/tools/facades/search_run.test.ts tests/tools/facades/search_index.test.ts`.
- 2025-10-31 : ‚úÖ Extractor langue hint + cap PDF stabilis√© (segments overflow ignor√©s) ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/extractor.test.ts`.
- 2025-10-31 : ‚úÖ Normalizer NFC + hash de d√©dup + fallback titre ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/normalizer.test.ts`.
- 2025-10-31 : ‚úÖ Ingestion KG d√©doubl√©e (Set) + vector store fusion titre/paragraphe valid√©es ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/ingest.toKnowledgeGraph.test.ts tests/unit/search/ingest.toVectorStore.test.ts`.
- 2025-10-31 : ‚úÖ Pipeline p-limit + fa√ßades search.* (snapshots + meta help) ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/pipeline.test.ts tests/tools/facades/search_run.test.ts tests/tools/facades/search_index.test.ts tests/tools/facades/search_status.test.ts`.
- 2025-10-31 : ‚úÖ Script setup-environment ‚Üí dossiers runtime `validation_run/` + `children/`, valeur par d√©faut `MCP_LOG_FILE`, avertissements Searx/Unstructured ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/scripts.setup-environment.test.ts`.
- 2025-10-31 : ‚úÖ EventStore payload versionn√© + troncature message `search:error` valid√©es ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/eventStore.test.ts`.
- 2025-10-31 : ‚úÖ Search metrics labels `{step,contentType,domain}` + SSE broadcast debounce test√©s ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/metrics.test.ts tests/monitor.dashboard.streams.test.ts`.
- 2025-11-02 : ‚úÖ Migration automatique `validation_runs/` ‚Üí `validation_run/`, documentation des gardes (canonicalisation, sniff MIME, conditional GET) et ajout du test de non-r√©gression ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/validationRun.layout.test.ts`.
- 2025-11-02 : ‚úÖ Int√©gration `search.run` (pipeline r√©el + mocks r√©seau) couvrant ingestion, avertissements typ√©s et `jobId` d√©terministe ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/integration/search/search_run.integration.test.ts`.
- 2025-11-02 : ‚úÖ Garde d‚Äôidempotence `(s,p,o)` pour le Knowledge Graph + tests `withProvenance` renforc√©s, couverture vectorielle sur `document_id`/`docId` et docId vide ignor√© ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/knowledge/knowledgeGraph.test.ts tests/unit/memory/vector.test.ts`.
- 2025-11-02 : ‚úÖ Ajout du test de charge `monitor/dashboard` garantissant le cap des domaines top 20 et la stabilit√© des m√©triques search ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/monitor.dashboard.streams.test.ts`.
- 2025-11-02 : ‚úÖ Scripts `run-search-e2e.ts` et `run-search-smoke.ts` persistants vers `validation_run/` (artefacts complets) + helper `scripts/lib/searchArtifacts.ts` + test `searchArtifacts`; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/scripts/searchArtifacts.test.ts`.
- 2025-11-02 : ‚úÖ Sant√© `docker-compose.search.yml` (healthcheck Node pour `server`, r√©seau interne, proxy document√©) + env defaults Searx align√©s (`mojeek`, robots.txt) ; commande `npm run test -- tests/scripts.setup-environment.test.ts`.
- 2025-11-02 : ‚úÖ Test e2e artefacts (`S91_search_e2e`) garantissant l'√©criture compl√®te sous `validation_run/` ; commande `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/scripts.run-search-e2e.test.ts`.
- 2025-11-02 : ‚úÖ E2E pipeline `search_run.e2e` couvrant ingestion S01, idempotence S05 (docIds stables, KG sans duplication) et erreurs robots/taille S06 ; commande `TSX_EXTENSIONS=ts SEARCH_E2E_ALLOW_RUN=1 MCP_TEST_ALLOW_LOOPBACK=yes node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/e2e/search/search_run.e2e.test.ts`.

- 2025-11-02 : ‚úÖ Couverture compl√®te (`npm run coverage`) confirmant ‚â•90‚ÄØ% sur `src/search/**`, ‚â•85‚ÄØ% global et snapshots stables ; commande `npm run coverage`.
- 2025-11-02 : ‚úÖ Documentation de `START_MCP_BG` (mise √† jour scripts/setup-agent-env.sh + docs/validation-run-runtime.md) ; commande `npm run test -- tests/scripts.setup-environment.test.ts`.
- 2025-11-02 : ‚úÖ Retrait du script obsol√®te `scripts/initValidationRun.ts` (code mort) et v√©rification `npm run lint`.
- 2025-11-02 : ‚úÖ Suppression des artefacts morts `tmp_before.txt` et dossiers `tmp/` suivis, mise √† jour de la garde d‚Äôhygi√®ne, puis ex√©cution `npm run test -- tests/hygiene.todo-scan.test.ts`.
- 2025-11-02 : ‚úÖ Nettoyage des exports obsol√®tes (`listArtifacts`, `formatChildMessages`, types `PromptVariablesInput`/`ToolSuccess`/`ToolError` et alias ID g√©n√©riques) ; commande `npm run lint:dead-exports`.
- 2025-11-02 : ‚ôªÔ∏è Purge des alias inutilis√©s (cancellation, fsArtifacts, tracing, MCP info), restauration du helper `fail()` canonique et r√©duction de l'allowlist des exports morts ; commande `npm run lint:dead-exports`.
- 2025-11-02 : ‚úÖ Retrait de `registerLessonRegression`, de l'alias `DashboardStigmergyRow` et du writer `writeArtifactFile`, nettoyage README/allowlist corr√©l√©s ; commandes `npm run lint:dead-exports` et `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/learning/lessonsRegressions.test.ts`.
- 2025-11-02 : ‚úÖ Ajout de `p-limit` comme d√©pendance runtime, retrait des alias TypeScript morts (BT inputs, planner inputs, RPC buildJsonRpcErrorResponse/JsonRpcValidationError), r√©-annotation du pipeline `p-limit` et nettoyage de l'allowlist ; commandes `npm run lint:dead-exports` et `npm run test -- tests/planner/compile.test.ts`.
