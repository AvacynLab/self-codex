----------
Voici ta **liste de t√¢ches exhaustive et hi√©rarchis√©e (√† cocher)**, **adress√©e directement √† toi, Agent**, pour **d√©velopper** et **int√©grer** le moteur de recherche LLM bas√© sur **SearxNG**, avec extraction **unstructured.io**, **injection graphe de connaissances** et **RAG**, dans le projet existant (orchestrateur MCP).
Chaque t√¢che pr√©cise **quoi faire**, **o√π (fichier par fichier)**, **avec sous-√©tapes**, ainsi que **les exigences tests & build** √† respecter.

---

## üéØ Brief (lis √ßa d‚Äôabord)

**Objectif g√©n√©ral**
Tu vas cr√©er un **module de recherche multimodal isol√©** (comme le module Graph), bas√© sur **SearxNG** (instance **self-hosted**), qui :

1. interroge SearxNG,
2. t√©l√©charge les contenus (HTML/PDF/Images‚Ä¶),
3. les **structure** via **unstructured.io**,
4. **alimente le graphe** (triples + provenance) et **le RAG** (chunks + embeddings),
5. expose des **MCP tools** (`search.run`, `search.index`, `search.status`),
6. est **observ√©**, **budgetis√©**, **s√©curis√©**, et **test√©** e2e.

**Correctifs attendus / contraintes**

* Respecte l‚ÄôESM, TS strict, `exactOptionalPropertyTypes`, budgets/timeout, idempotence HTTP, logs structur√©s, events `EventStore`.
* Pas de `undefined` dans les sorties publiques ; **cl√©s omises** uniquement.
* D√©duplique contenus/segments ; limite la taille t√©l√©charg√©e ; **respect robots.txt** (si activ√©).
* **Self-host SearxNG** + **unstructured server** via **docker-compose** (dev & CI).
* **Tests unitaires, int√©gration, e2e** (avec mocks et avec containers r√©els).
* Int√©gration Dashboard : SSE live, m√©triques p50/p95/p99.

---

## üß≠ Plan global (phases)

* [x] **A. Infrastructure** : docker-compose (SearxNG + Unstructured + Server), env, settings.yml
* [x] **B. Module `src/search`** : clients, pipeline, ingestion Graph/RAG, cache
* [x] **C. Tools MCP** : `search.run`, `search.index`, `search.status` + registry
* [x] **D. Int√©gration orchestrateur** : runtime, events, dashboard
* [x] **E. S√©curit√©/Robots/Rate-limit**
* [ ] **F. Tests** (unit, integ, e2e), fixtures, coverage, CI *(reste : ex√©cution docker r√©elle + suivi couverture/CI)*
* [x] **G. Docs & Runbook**
* [ ] **H. Nettoyage & v√©rifs finales** *(reste : fum√©e docker + validations manuelles)*

---

## A) Infrastructure : SearxNG & Unstructured (self-host)

### `docker/docker-compose.search.yml` **(NOUVEAU)**

* [x] Cr√©e un compose d√©di√© avec 3 services : `searxng`, `unstructured`, `server`.

  * [x] `searxng`

    * [x] Image : `searxng/searxng:latest`
    * [x] Volumes : `./searxng/settings.yml:/etc/searxng/settings.yml:ro`
    * [x] Ports : `127.0.0.1:8080:8080`
    * [x] Healthcheck : `GET /healthz` (ou page d‚Äôaccueil), interval 10s, retries 6
    * [x] Resources : limites CPU/RAM (√©viter OOM en CI)
  * [x] `unstructured`

    * [x] Image : `quay.io/unstructured-io/unstructured-api:latest`
    * [x] Ports : `127.0.0.1:8000:8000`
    * [x] Healthcheck : `POST /general/v0/general` (ping minimal)
  * [x] `server`

    * [x] Build : Dockerfile existant du serveur MCP
    * [x] Depends_on : `searxng`, `unstructured` (condition: service_healthy)
    * [x] Env : variables `SEARCH_*`, `UNSTRUCTURED_*` (cf. config)
* [x] Ajoute un **r√©seau bridge interne** (ex: `search_net`) pour isoler.
* [x] Cible `dev` et `ci` (fichiers override si besoin).

### `docker/searxng/settings.yml` **(NOUVEAU)**

* [x] Configure `engines` pertinents (general/news/images/files/science/it), `categories`, `safe_search=0` (ou 1 selon besoin), `tokens`, `retries`.
* [x] D√©sactive/active engines selon conformit√© (pas d‚ÄôAPIs non licenci√©es).
* [x] Active `result_proxy` si souhait√© (utile pour fetch via proxy interne).
* [x] `server: { secret_key: "‚Ä¶" }` (mont√© via secret en prod).

### `env/.env.example` **(MODIFIER/CR√âER)**

* [x] Ajouter :

  * [x] `SEARCH_SEARX_BASE_URL=http://searxng:8080`
  * [x] `SEARCH_SEARX_API_PATH=/search`
  * [x] `SEARCH_SEARX_TIMEOUT_MS=15000`
  * [x] `SEARCH_SEARX_ENGINES=bing,ddg,wikipedia,arxiv,github` *(exemple)*
  * [x] `SEARCH_SEARX_CATEGORIES=general,news,images,files`
  * [x] `UNSTRUCTURED_BASE_URL=http://unstructured:8000`
  * [x] `UNSTRUCTURED_TIMEOUT_MS=30000`
  * [x] `UNSTRUCTURED_STRATEGY=hi_res`
  * [x] `SEARCH_FETCH_TIMEOUT_MS=20000`
  * [x] `SEARCH_FETCH_MAX_BYTES=15000000`
  * [x] `SEARCH_FETCH_UA=CodexSearchBot/1.0`
  * [x] `SEARCH_INJECT_GRAPH=true`
  * [x] `SEARCH_INJECT_VECTOR=true`

---

## B) Module `src/search` (isol√©, comme `graph/`)

> Tous ces fichiers sont **NOUVEAUX** √† moins d‚Äôexister d√©j√†.

### `src/search/types.ts`

* [x] Impl√©mente **types pivot** : `SearxResult`, `RawFetched`, `StructuredSegment`, `StructuredDocument`.
* [x] **Sous-t√¢ches**

  * [x] `StructuredSegment.kind` (title/paragraph/list/table/figure/caption/code/meta)
  * [x] `StructuredDocument.provenance` (engines, categories, searxQuery)
  * [x] Pas de champs `undefined` dans les types publics.

### `src/search/config.ts`

* [x] Centralise **env** et valeurs par d√©faut (cf. `.env.example`).
* [x] **Sous-t√¢ches**

  * [x] Parser `engines`/`categories` (CSV ‚Üí array sans vides).
  * [x] Export `SearchConfig` (searx, unstructured, fetch, pipeline).

### `src/search/searxClient.ts`

* [x] Client **SearxNG JSON** (`format=json`).
* [x] **Sous-t√¢ches**

  * [x] `searxQuery(q, {categories, engines, count})`
  * [x] Validation stricte de la r√©ponse (zod).
  * [x] Timeout, headers (auth bearer si configur√©), retries basiques (2).

### `src/search/downloader.ts`

* [x] T√©l√©chargement HTTP **robuste** (follow, clampsize, type sniff).
* [x] **Sous-t√¢ches**

  * [x] `fetchUrl(url)` ‚Üí `RawFetched` (headers normalis√©s, `contentType` sans charset)
  * [x] `computeDocId(url, headers)` ‚Üí SHA256(url+ETag+Last-Modified)
  * [x] Option **robots.txt** (si activ√© dans config)
  * [x] Rejets : `status >= 400`, contenus > `maxContentBytes`.

### `src/search/extractor.ts`

* [x] Client **unstructured.io** (endpoint `/general/v0/general`).
* [x] **Sous-t√¢ches**

  * [x] Multipart upload du **buffer** t√©l√©charg√©, `strategy=hi_res` (param)
  * [x] Mapping √©l√©ments ‚Üí `StructuredSegment` (incl. page, bbox, meta)
  * [x] D√©tection **langue** (lib simple : tinyld)
  * [x] Gestion images/PDF/HTML (laisser faire unstructured; passer `content_type`).

### `src/search/normalizer.ts`

* [x] **Nettoyage** & **d√©dup**.
* [x] **Sous-t√¢ches**

  * [x] `finalizeDocId(doc)` (remplace `id: 'tmp'`)
  * [x] `deduplicateSegments(doc)` (hash `(kind|text.trim)`).

### `src/search/ingest/toKnowledgeGraph.ts`

* [x] Ingestion **doc ‚Üí triples** (Document type, title, source, language, provenance).
* [x] **Sous-t√¢ches**

  * [x] Appelle `knowledge/knowledgeGraph.ts`: `upsertTriple`, `withProvenance`.
  * [x] `mentions` (MVP) via `extractKeyTerms(doc)` ; pr√©voir hook NER/LLM plus tard.
  * [x] **Provenance** obligatoire (sourceUrl, fetchedAt).

### `src/search/ingest/toVectorStore.ts`

* [x] Ingestion **chunks ‚Üí embeddings**.
* [x] **Sous-t√¢ches**

  * [x] S√©lectionne segments `paragraph|title|list`, `.trim()`
  * [x] Chunking par tokens si util dispo (`memory/chunking.ts`)
  * [x] `embedText({ idHint, text, metadata })` ‚Üí `memory/vector.ts`.

### `src/search/pipeline.ts`

* [x] Orchestrateur **end-to-end** (query ‚Üí fetch ‚Üí extract ‚Üí normalize ‚Üí ingest).
* [x] **Sous-t√¢ches**

  * [x] `runSearchJob(params)` : √©met events `search:*` sur `eventStore`.
  * [x] Respect `maxResults`, parall√©lismes (`parallelFetch`, `parallelExtract`).
  * [x] Catch/emit `search:error { url, error }` et continue.

### `src/search/cache/contentCache.ts` *(optionnel, recommand√©)*

* [x] Cl√©: `url + (etag|last-modified)` ; TTL par **domaine** ; backoff sur 4xx/5xx.

### `src/search/metrics.ts`

* [x] Int√®gre `infra/tracing.ts` : histogrammes `p50/p95/p99` pour `searxQuery`, `fetchUrl`, `extractWithUnstructured`, `ingest*`.

### `src/search/index.ts`

* [x] Fa√ßade d‚Äôexport (unique point d‚Äôentr√©e du module).

---

## C) Tools MCP (exposition contr√¥l√©e)

### `src/tools/search_run.ts` **(NOUVEAU)**

* [x] Tool **`search.run`** (zod input, budgets, description).
* [x] Appelle `runSearchJob`.
* [x] **Retour** : `{ ok, count, docs:[{id,url,title,language}] }`.
* [x] **Tests** : mock clients + snapshot r√©ponse.

### `src/tools/search_index.ts` **(NOUVEAU)**

* [x] Tool **`search.index`** (ing√©rer URL(s) directes sans Searx).
* [x] Boucle `fetch ‚Üí extract ‚Üí normalize ‚Üí ingest`.
* [x] **Retour** : `{ ok, docs:[{id,url,title}] }`.

### `src/tools/search_status.ts` **(NOUVEAU)**

* [x] Tool **`search.status`** (si jobs persistent) ; sinon renvoie non impl√©ment√© proprement.

### `src/mcp/registry.ts` **(EXISTANT, MODIFIER)**

* [x] Enregistre les 3 tools dans **pack** (`authoring` ou `ops`).
* [x] **Budgets**: `timeMs`, `toolCalls`, `bytesOut` ; **tags** (`search`,`web`,`ingest`,`rag`).
* [x] **Docs** : title/description clairs + exemples d‚Äôappel.

---

## D) Int√©gration orchestrateur & observabilit√©

### `src/orchestrator/runtime.ts` **(EXISTANT, MODIFIER)**

* [x] Injecte le module `search/` dans la composition (si pattern d√©j√† en place).
* [x] Passe `eventStore`, `logger`, `tracing` au pipeline.
* [x] Ajoute teardown propre si ressources (rien de sp√©cial attendu c√¥t√© clients HTTP).

### `src/eventStore.ts` **(EXISTANT, MODIFIER)**

* [x] Ajoute **kinds** : `search:job_started`, `search:doc_ingested`, `search:error`, `search:job_completed`.
* [x] Stabilise la **s√©rialisation JSON** (cl√©s ordonn√©es si votre infra le requiert).

### `src/monitor/dashboard.ts` **(EXISTANT, MODIFIER)**

* [x] **Panneaux** :

  * [x] File jobs (en cours/termin√©s) + docs/min + erreurs par type
  * [x] Heatmap domaines les plus consult√©s
  * [x] Latence moyenne par `contentType` (HTML/PDF/Image)

### `src/http/*` **(EXISTANT, V√âRIFIER)**

* [x] Si tools expos√©s via HTTP, s‚Äôassurer :

  * [x] **Idempotence** (cl√© = hash(query,categories,engines,maxResults))
  * [x] **Rate-limit** d√©di√© `search.*`.

---

## E) S√©curit√©, conformit√© & robustesse

* [x] **User-Agent** explicite (`SEARCH_FETCH_UA`).
* [x] **robots.txt** (si activ√©) + **throttle** par domaine.
* [x] **Max bytes** strict (15MB par d√©faut).
* [x] **Timeouts** coh√©rents (fetch/extract/job).
* [x] **Redaction** des secrets dans logs. *(tests runtime optional contexts ‚úÖ)*
* [x] **Allow-list** des env inject√©es si exec enfant (pas pr√©vu ici).
* [x] **Provenance** obligatoire sur triples.
* [x] **Conformit√©** licences engines Searx (d√©sactiver ceux √† risque).

---

## F) Tests (tu dois les √©crire et les faire passer)

> Suis les **contraintes build/tests** en fin de document.

### Unitaires (Mocha + TS)

#### `test/unit/search/searxClient.spec.ts`

* [x] Mock r√©ponses SearxNG (cas OK / schema invalide / timeout / 500).
* [x] V√©rifie **zod parsing**, params de requ√™te (engines/categories/count).

#### `test/unit/search/downloader.spec.ts`

* [x] Content-type sniff, clamp taille, follow redirects, erreurs 4xx/5xx.
* [x] `computeDocId` (ETag, Last-Modified) ‚Äî golden tests.

#### `test/unit/search/extractor.spec.ts`

* [x] Mock **unstructured** (√©l√©ments vari√©s : title/paragraph/list/table/figure).
* [x] Mapping vers `StructuredSegment`, d√©tection langue.

#### `test/unit/search/normalizer.spec.ts`

* [x] D√©duplication segments, finalisation id.

#### `test/unit/search/ingest.toKnowledgeGraph.spec.ts`

* [x] Appels `upsertTriple` + `withProvenance` (spies).
* [x] `mentions`: extraction tokens fr√©quents (stopwords FR/EN basiques).

#### `test/unit/search/ingest.toVectorStore.spec.ts`

* [x] D√©coupage, appel `embedText` par chunk avec metadata.

#### `test/unit/search/pipeline.spec.ts`

* [x] Pipeline heureux (tout OK) + cas d‚Äôerreur isol√©e (un URL √©choue), v√©rifie **events** √©mis.

### Int√©gration (sans containers r√©els)

* [x] Mocks HTTP **SearxNG** & **Unstructured** (nock).
* [x] `search.run` tool : entr√©e ‚Üí docs ing√©r√©s ‚Üí v√©rifie appels Graph/RAG.

### E2E (avec `docker-compose.search.yml`)

*‚ö†Ô∏è* La suite s'ex√©cute uniquement si `SEARCH_E2E_ALLOW_RUN=1` (automatiquement d√©fini par `npm run test:e2e:search`). Sans ce flag,
 elle se mettra en `SKIP` pour √©viter les faux n√©gatifs lorsque Docker/Unstructured ne sont pas disponibles.

* [ ] Lancer **searxng + unstructured + server**.
* [ ] Appeler `search.run { query: "site:arxiv.org LLM 2025 filetype:pdf", categories:["files","general"], maxResults:4 }`.
* [ ] Attendre compl√©tion ‚Üí v√©rifier :

  * [ ] au moins 1 doc ing√©r√© dans **graphe** (triples Document + provenance).
  * [ ] au moins 1 embedding dans **vector store** avec metadata correcte.
  * [ ] events dans **dashboard** (ou endpoint JSON de stats).

### Couverture & qualit√©

* [x] **Coverage global ‚â• 85%**, `src/search/*` ‚â• 90%.
* [x] Pas de tests flakys (timeouts stables, retries mock√©s).
* [x] Tests typ√©s strict (no `any` implicite, `exactOptionalPropertyTypes` respect√©).

---

## G) Documentation & Runbook

### `docs/search-module.md` **(NOUVEAU)**

* [x] Overview, architecture, sch√©mas.
* [x] Variables d‚Äôenv + valeurs par d√©faut.
* [x] Exemples d‚Äôappels `search.run`/`search.index`.
* [x] Strat√©gies de **re-crawl** (ETag, TTL par domaine).
* [x] Limites connues (images OCR lourdes, PDFs scann√©s).
* [x] **Playbook incident** (unstructured down, searxng rate-limited).

### `CHANGELOG.md` **(MODIFIER)**

* [x] Ajoute entr√©e `feature: search llm searxng`.

---

## H) Nettoyage & v√©rifications finales

* [x] Enl√®ve **placeholders**/TODO non trait√©s ou ouvre tickets.
* [x] Pas de `console.log` brut ‚Üí **logger** central.
* [x] V√©rifie **exact optional** (aucun `undefined` expos√©).
* [x] V√©rifie **budgets** tools (`timeMs`, `bytesOut`, `toolCalls`).
*‚ö†Ô∏è* **Smoke test** local (compose up, `search.run`, dashboard OK). *(script `npm run smoke:search` pr√™t ; reste bloqu√© sans Docker dans l'environnement agent)*

---

# üìÅ D√©tail **fichier par fichier** (avec objectifs & attentes de tests)

> **NOUVEAUX**

* [x] `src/search/types.ts` ‚Äî **Objectif** : contrat pivot des donn√©es.

  * **Attendu tests** : types utilis√©s sans `any`, pas d‚Äô`undefined` en sortie.

* [x] `src/search/config.ts` ‚Äî **Objectif** : config centralis√©e, valeurs par d√©faut s√ªres.

  * **Attendu tests** : parsing CSV, num√©riques, bool√©ens ; fallback OK.

* [x] `src/search/searxClient.ts` ‚Äî **Objectif** : requ√™ter SearxNG proprement.

  * **Attendu tests** : zod schema, erreurs r√©seau, params q/cat/engines.

* [x] `src/search/downloader.ts` ‚Äî **Objectif** : fetching robuste (clamp, type).

  * **Attendu tests** : redirects, status 404/500, clamp, content-type.

* [x] `src/search/extractor.ts` ‚Äî **Objectif** : mapper unstructured ‚Üí segments.

  * **Attendu tests** : diversit√© √©l√©ments, langue, erreurs 5xx.

* [x] `src/search/normalizer.ts` ‚Äî **Objectif** : id stable, d√©dup segments.

  * **Attendu tests** : collisions √©vit√©es, d√©dup correcte.

* [x] `src/search/ingest/toKnowledgeGraph.ts` ‚Äî **Objectif** : triples + provenance.

  * **Attendu tests** : appels `upsertTriple` exacts, pr√©sence provenance.

* [x] `src/search/ingest/toVectorStore.ts` ‚Äî **Objectif** : embeddings avec metadata.

  * **Attendu tests** : nombre de chunks, metadata compl√®te (docId,url,title,language,fetchedAt).

* [x] `src/search/pipeline.ts` ‚Äî **Objectif** : orchestration + events.

  * **Attendu tests** : s√©quence d‚Äôappels, events `search:*`, r√©silience sur erreurs URL.

* [x] `src/search/metrics.ts` ‚Äî **Objectif** : timers/histogrammes branch√©s.

  * **Attendu tests** : counters incr√©ment√©s, labels corrects.

* [x] `src/search/index.ts` ‚Äî **Objectif** : export public propre.

  * **Attendu tests** : import unique depuis ailleurs compile.

* [x] `src/tools/search_run.ts` ‚Äî **Objectif** : tool MCP principal.

  * **Attendu tests** : validation input, budgets, retour docs.

* [x] `src/tools/search_index.ts` ‚Äî **Objectif** : ingestion directe URL(s).

  * **Attendu tests** : liste d‚ÄôURL, erreurs isol√©es, retours agr√©g√©s.

* [x] `src/tools/search_status.ts` ‚Äî **Objectif** : introspection jobs (si persist√©s).

  * **Attendu tests** : job not found / job done.

* [x] `docker/docker-compose.search.yml` ‚Äî **Objectif** : dev & CI e2e.

  * **Attendu tests** : healthchecks OK, services up avant e2e.

* [x] `docker/searxng/settings.yml` ‚Äî **Objectif** : engines sains.

  * **Attendu tests** : requ√™tes simples retournent r√©sultats.

* [x] `docs/search-module.md` ‚Äî **Objectif** : runbook complet.

  * **Attendu** : explicite, reproductible.

> **EXISTANTS (√† MODIFIER)**

* [x] `src/mcp/registry.ts` ‚Äî **Objectif** : enregistrer les 3 tools avec budgets/tags.

  * **Attendu tests** : `tools help` liste bien search.* avec metadata.

* [x] `src/orchestrator/runtime.ts` ‚Äî **Objectif** : injecter module search et wiring `eventStore/tracing`.

  * **Attendu tests** : pas de r√©gression sur autres modules, hooks OK.

* [x] `src/eventStore.ts` ‚Äî **Objectif** : nouveaux kinds `search:*` stabilis√©s.

  * **Attendu tests** : s√©rialisation stable (ordre cl√©), SSE fonctionne.

* [x] `src/monitor/dashboard.ts` ‚Äî **Objectif** : panneaux search.

  * **Attendu tests** : endpoints JSON renvoient stats ; UI affiche docs/min & erreurs.

* [x] `knowledge/knowledgeGraph.ts` ‚Äî **Objectif** : garantir `upsertTriple` + `withProvenance`.

  * **Attendu tests** : triplets persist√©s, duplication √©vit√©e.

* [x] `memory/vector.ts` ‚Äî **Objectif** : `embedText` stable, capacity caps respect√©es.

  * **Attendu tests** : taille index plafonn√©e, recherche par similarit√© OK.

---

## üß™ Exigences **Tests & Build** (√† respecter partout)

**Build**

* [x] Node **‚â• 20**, ESM strict, TS **strict** + `exactOptionalPropertyTypes: true`.
* [x] `npm run build` compile sans warn ; **aucun** `any` implicite.
* [x] Pas de d√©pendances non d√©clar√©es ; imports Node en `node:`.
* [x] `graph-forge` / workers : inchang√©s (pas d‚Äôimpact).

**Lint & qualit√©**

* [x] Lint passe (r√®gles hygi√®ne existantes). *(command√© le 2025-11-12 via `npm run lint`)*
* [x] Aucune cl√© optionnelle exposant `undefined` dans JSON public.
* [x] JSON stable (ordre des champs si n√©cessaire c√¥t√© EventStore).

**Tests**

* [x] **Unit ‚â• 90%** sur `src/search/*`, **Global ‚â• 85%**. *(confirm√© via `npm run coverage` le 2025-11-13)*
* [x] **Int√©gration** : mocks HTTP (`nock`) pour SearxNG/Unstructured.
* [x] **E2E** : `docker-compose.search.yml` ‚Äî script unique `npm run test:e2e:search`.
* [ ] **CI** : job d√©di√© qui monte compose, attend health, lance tests, publie couverture & logs.

**Observabilit√©**

* [x] Tracing : latences `searxQuery`, `fetchUrl`, `extractWithUnstructured`, `ingest*`.
* [x] EventStore : `search:job_*`, `search:error` ; Dashboard affiche tendances.

**S√©curit√© & conformit√©**

* [x] **robots.txt** (si activ√©), throttle, user-agent.
* [x] Auth bearer vers SearxNG si requis par env (prod).
* [x] Redaction logs (en-t√™tes sensibles).
* [x] Respect licences engines (d√©sactiver ceux qui posent probl√®me).

---

## ‚úÖ Mini sc√©nario de validation (manuel)

* [ ] Lancer `docker compose -f docker/docker-compose.search.yml up -d`
* [ ] Appeler `search.run` avec :

```json
{
  "query": "benchmarks LLM multimodal 2025 filetype:pdf",
  "categories": ["files","general","images"],
  "maxResults": 6,
  "fetchContent": true,
  "injectGraph": true,
  "injectVector": true
}
```

* [ ] Observer :

  * [ ] ‚â•1 doc dans graphe (triples + provenance)
  * [ ] ‚â•1 embedding en vector store
  * [ ] Dashboard: docs/min > 0, erreurs = 0, latences raisonnables

---

Si tu coches ces cases dans l‚Äôordre, on obtient un **moteur de recherche LLM** **robuste**, **int√©gr√© proprement**, **observ√©** et **test√©**, pr√™t pour l‚Äôorchestration multi-agents.
---

### Historique Agent (2025-10-31)
- Extension du pipeline avec ingestion directe (`ingestDirect`) et factorisation du traitement fetch/extract/ingest pour r√©utilisation par les fa√ßades.
- Ajout des tools `search.index` et `search.status`, des sch√©mas RPC associ√©s et des tests de fa√ßade couvrant succ√®s, budgets √©puis√©s et validation.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/pipeline.test.ts tests/tools/facades/search_index.test.ts tests/tools/facades/search_status.test.ts` ‚úÖ.
### Historique Agent (2025-11-01)
- Int√©gration du pipeline search dans l'orchestrateur (config env, clients, enregistrements des tools `search.*`).
- Ajout du panneau search au dashboard (file jobs, domaines, latence contenu) avec export testable.
- Mise √† jour des manifests/budgets search et des tests cibl√©s (dashboard, golden tools).

### Historique Agent (2025-11-02)
- R√©daction du runbook `docs/search-module.md` (architecture, configuration, exemples d'usage, strat√©gies d'exploitation).
- Cr√©ation de l'entr√©e `feature: search llm searxng` dans `CHANGELOG.md` pour tracer l'arriv√©e du module de recherche.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ.

### Historique Agent (2025-11-03)
- Mise en place d'un throttle par domaine dans le downloader (`SEARCH_FETCH_DOMAIN_DELAY_MS`) et extension des exemples d'env/expected keys.
- Ajout du test d'int√©gration `tests/integration/search/search_run.integration.test.ts` avec mocks HTTP `nock` couvrant l'ingestion Graph/RAG et instrumentation.
- D√©claration de la d√©pendance `nock` et mise √† jour des checklists associ√©es.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/downloader.test.ts tests/integration/search/search_run.integration.test.ts` ‚úÖ.

### Historique Agent (2025-11-04)
- Cr√©ation du script `scripts/run-search-e2e.mjs` orchestrant le `docker-compose` d√©di√© puis l'ex√©cution cibl√©e du test e2e search.
- Ajout du test `tests/e2e/search/search_run.e2e.test.ts` (serveurs stub Searx + contenu, pipeline r√©el avec unstructured) et du script `npm run test:e2e:search`.
- Mise √† jour de la checklist AGENTS (case E2E) et ex√©cution : `npm run test:e2e:search` ‚ö†Ô∏è (docker absent ‚Üí suite ignor√©e proprement), `npm run typecheck` ‚úÖ.

### Historique Agent (2025-11-05)
- Ajout du cache de contenu (`src/search/cache/contentCache.ts`) avec TTL par domaine, backoff 4xx/5xx et clonage des payloads.
- Extension de la configuration fetch (env, docs, expected keys) + support du backoff c√¥t√© downloader (`DownloadBackoffError`) et tests associ√©s.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/downloader.test.ts tests/unit/search/cache/contentCache.test.ts` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/config.test.ts` ‚úÖ.

### Historique Agent (2025-11-06)
- Renforcement de l'idempotence des fa√ßades `search.run`/`search.index` via une cl√© d√©terministe (hash des param√®tres structurants) lorsqu'aucune cl√© n'est fournie.
- Ajout d'un limiteur HTTP d√©di√© `search.*` (env `MCP_HTTP_SEARCH_RATE_LIMIT_*`), tests int√©gration rate-limit, et documentation du comportement.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/tools/facades/search_run.test.ts tests/tools/facades/search_index.test.ts tests/http/http_rate_limit.test.ts` ‚ùå (√©chec transform esbuild/TLA, limitation environnementale).

### Historique Agent (2025-11-07)
- Ajout des variables d'environnement optionnelles `SEARCH_SEARX_AUTH_TOKEN`, `SEARCH_SEARX_MAX_RETRIES` et `UNSTRUCTURED_API_KEY` dans les templates `.env`, avec synchronisation des cl√©s attendues.
- V√©rification de la configuration et documentation mise √† jour dans `AGENTS.md` (cases auth bearer/tests unitaires search marqu√©es compl√®tes).
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/config.test.ts` ‚úÖ.

### Historique Agent (2025-11-08)
- Facteur le fast-path HTTP pour charger `server.ts` de mani√®re paresseuse, contournant l'√©chec esbuild sur `await` de haut niveau tout en conservant les hooks idempotence/logs.
- Ajout d'un repli contr√¥l√© lorsque le contr√¥leur n'est pas initialis√© et documentation des traces debug, puis installation des d√©pendances manquantes (`tinyld`) afin que l'import dynamique r√©ussisse en test.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/tools/facades/search_run.test.ts tests/tools/facades/search_index.test.ts tests/http/http_rate_limit.test.ts` ‚úÖ.

### Historique Agent (2025-11-09)
- Revue compl√®te du backlog search : cases globales mises √† jour, sections s√©curit√©/tests annot√©es, et historique r√©duit √† <50 lignes pour les prochains agents.
- V√©rification infrastructure/observabilit√© (compose, dashboard, registry) et documentation des t√¢ches restantes (CI, logs sensibles, fum√©e docker).
- Tests ex√©cut√©s : `npm run build` ‚úÖ.

### Historique Agent (2025-11-10)
- Mise en place de la redaction automatique des secrets search (token Searx/unstructured) via la configuration runtime et expose des helpers internes pour tests.
- Ajout d'un collecteur de tokens dans la config search + tests unitaires garantissant le d√©doublonnage/trim.
- Tests ex√©cut√©s : `npm run typecheck` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/unit/search/config.test.ts` ‚úÖ ; tentative `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/orchestrator/runtime.optional-contexts.test.ts` ‚ùå (limitation esbuild sur top-level await malgr√© correctif pr√©c√©dent).

### Historique Agent (2025-11-11)
- Factorisation de l'initialisation du runtime orchestrateur (`runtimeReady`) pour supprimer les `await` de haut niveau et prot√©ger l'acc√®s aux outils/pipelines tant que l'initialisation n'est pas termin√©e.
- Mise √† jour des fa√ßades JSON-RPC/serveur pour attendre l'initialisation, rafra√Æchissement du test `runtime.optional-contexts` et import des secrets search dans la redaction des logs.
- Tests ex√©cut√©s : `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/orchestrator/runtime.optional-contexts.test.ts` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/tools/facades/search_run.test.ts tests/tools/facades/search_index.test.ts tests/http/http_rate_limit.test.ts` ‚úÖ ; `npm run typecheck` ‚úÖ.

### Historique Agent (2025-11-12)
- Ajout d'un garde-fou `SEARCH_E2E_ALLOW_RUN` : la suite `tests/e2e/search/search_run.e2e.test.ts` se met en SKIP par d√©faut et ne s'ex√©cute qu'√† travers `npm run test:e2e:search` qui active le flag et orchestre Docker.
- Documentation `docs/search-module.md` mise √† jour pour refl√©ter le nouveau comportement, et checklist AGENTS annot√©e pour √©viter les faux n√©gatifs en environnement sans Docker.
- Tests ex√©cut√©s : `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/e2e/search/search_run.e2e.test.ts` ‚úÖ (SKIP attendu) ; `npm run lint` ‚úÖ.

### Historique Agent (2025-11-13)
- Relance compl√®te de la couverture (`npm run coverage`) afin de valider le nouveau garde agr√©g√© `scripts/checkSearchCoverage.ts` (>90¬†% sur `src/search/*`).
- Nettoyage du dossier `coverage/` et mise √† jour de la checklist (case couverture) pour refl√©ter la confirmation.
- Tests ex√©cut√©s : `npm run coverage` ‚úÖ (incluant `node --import tsx scripts/checkSearchCoverage.ts`).

### Historique Agent (2025-11-14)
- R√©installation des d√©pendances de d√©veloppement (`npm install --include=dev`) pour restaurer `tinyld` absent lors de la couverture compl√®te.
- Ex√©cution de `npm run coverage` ‚úÖ confirmant 91.16‚ÄØ% global et 92.64‚ÄØ% sur `src/search/*` (script `scripts/checkSearchCoverage.ts`).
- Commandes ex√©cut√©es suppl√©mentaires : `npm install` (r√©solution modules manquants).

### Historique Agent (2025-11-15)
- Factorisation du pilotage Docker dans `scripts/lib/searchStack.ts`, conversion du runner e2e en TypeScript et ajout du script fum√©e `scripts/run-search-smoke.ts`.
- Ajout du validateur `assessSmokeRun`, de tests unitaires (`tests/scripts/searchStack.test.ts`, `tests/scripts/searchSmokePlan.test.ts`) et de la commande `npm run smoke:search` document√©e.
- Tests ex√©cut√©s : `npm run lint` ‚úÖ ; `TSX_EXTENSIONS=ts node --import tsx ./node_modules/mocha/bin/mocha.js --reporter tap --file tests/setup.ts tests/scripts/searchStack.test.ts tests/scripts/searchSmokePlan.test.ts` ‚úÖ.

