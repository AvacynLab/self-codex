import { readFile, writeFile } from "node:fs/promises";
import path from "node:path";

import {
  type ScenarioTimingBucket,
  type ScenarioTimingReport,
} from "./artefacts.js";
import { ensureValidationRunLayout, type ValidationRunLayout } from "./layout.js";
import { formatScenarioSlug, resolveScenarioById } from "./scenario.js";

/**
 * Canonical validation stages requested by the checklist when exporting
 * `timings.json`. The array order is meaningful when rendering logs or reports
 * because it mirrors the execution flow of each scenario.
 */
export const SCENARIO_TIMING_STAGES = [
  "searxQuery",
  "fetchUrl",
  "extractWithUnstructured",
  "ingestToGraph",
  "ingestToVector",
] as const;

/** Union of the supported timing stage identifiers. */
export type ScenarioTimingStage = (typeof SCENARIO_TIMING_STAGES)[number];

/**
 * Samples collected while parsing artefacts or runtime traces. Each stage stores
 * the raw duration values (in milliseconds) so percentiles can be computed
 * deterministically. Documents and errors are gathered separately to honour the
 * checklist accounting requirements.
 */
export interface ScenarioMetricSamples {
  /** Recorded durations per stage (milliseconds). */
  readonly stageDurations: Partial<Record<ScenarioTimingStage, number[]>>;
  /** Optional list of total scenario runtimes (milliseconds). */
  readonly totalDurations: number[];
  /** Identifiers of the documents ingested during the scenario. */
  readonly documentIds: string[];
  /** Incremental counters extracted from summary events (when provided). */
  readonly documentCountIncrements: number[];
  /** Error categories observed while analysing the artefacts. */
  readonly errorCategories: string[];
}

/**
 * Additional knobs exposed when aggregating the final timing report. Operators
 * can override the strategy used to derive the `tookMs` field from the collected
 * samples.
 */
export interface BuildScenarioTimingReportOptions {
  /** Custom aggregator applied to the collected total durations. */
  readonly totalDurationAggregator?:
    | "max"
    | "p95"
    | "median"
    | ((durations: readonly number[]) => number);
}

/**
 * Describes how values should be extracted from raw event records. The default
 * configuration assumes a relatively flat JSON schema but fallbacks are
 * provided to cover nested payloads generated by orchestration layers.
 */
export interface ExtractScenarioMetricsOptions {
  /** Location of the stage identifier (defaults to `["stage"]`). */
  readonly stageExtractor?: ValueExtractor;
  /** Optional mapping to convert custom stage names to the canonical ones. */
  readonly stageMap?: Readonly<Record<string, ScenarioTimingStage>>;
  /** Location of the per-stage duration (defaults to `["durationMs"]`). */
  readonly durationExtractor?: ValueExtractor;
  /** Location of the scenario-level runtime (defaults to `["tookMs"]`). */
  readonly totalDurationExtractor?: ValueExtractor;
  /** Field exposing the document identifier. */
  readonly documentIdExtractor?: ValueExtractor;
  /** Field exposing an incremental document counter. */
  readonly documentCountExtractor?: ValueExtractor;
  /** Optional success flag to only count successful ingestion events. */
  readonly documentSuccessExtractor?: ValueExtractor;
  /** Values considered "successful" for the ingestion flag. Defaults to `[true, "success"]`. */
  readonly documentSuccessValues?: readonly unknown[];
  /** Field exposing the error category (defaults to `["category"]`). */
  readonly errorCategoryExtractor?: ValueExtractor;
}

/**
 * Combined options wiring extraction and aggregation helpers. Useful when
 * computing a full timing report from a single call.
 */
export interface ComputeScenarioMetricsOptions
  extends ExtractScenarioMetricsOptions,
    BuildScenarioTimingReportOptions {}

/**
 * Generic descriptor pointing at values in a record. Extractors can be simple
 * paths (e.g. `["metrics", "durationMs"]`) or custom functions when the
 * structure deviates from the defaults.
 */
type ScalarExtractor = readonly (string | number)[] | ((record: Record<string, unknown>) => unknown);

/** Value extractor supporting optional fallbacks. */
type ValueExtractor = ScalarExtractor | readonly ScalarExtractor[];

/**
 * Computes latency percentiles from the provided samples using linear
 * interpolation. The helper is deterministic and expects the input to be in
 * milliseconds.
 */
export function computeTimingBucket(samples: readonly number[]): ScenarioTimingBucket {
  if (samples.length === 0) {
    throw new Error("Cannot compute timing bucket from an empty sample set.");
  }

  const sorted = [...samples].sort((a, b) => a - b);
  return {
    p50: computePercentile(sorted, 50),
    p95: computePercentile(sorted, 95),
    p99: computePercentile(sorted, 99),
  };
}

/**
 * Builds the canonical `ScenarioTimingReport` from raw samples. Missing stages
 * generate diagnostic notes to guide operators when artefacts need further
 * analysis.
 */
export function buildScenarioTimingReport(
  samples: ScenarioMetricSamples,
  options: BuildScenarioTimingReportOptions = {},
): { readonly report: ScenarioTimingReport; readonly notes: readonly string[] } {
  const notes: string[] = [];
  const timings: Partial<Record<ScenarioTimingStage, ScenarioTimingBucket>> = {};

  const stageMaxima: number[] = [];
  for (const stage of SCENARIO_TIMING_STAGES) {
    const durations = samples.stageDurations[stage] ?? [];
    if (durations.length === 0) {
      notes.push(`Aucun échantillon de durée n'a été trouvé pour la phase ${stage}.`);
      continue;
    }

    try {
      const bucket = computeTimingBucket(durations);
      timings[stage] = bucket;
      stageMaxima.push(Math.max(...durations));
    } catch (error) {
      notes.push(
        `Impossible de calculer les percentiles pour ${stage}: ${(error as Error).message}`,
      );
    }
  }

  const totalDurations = samples.totalDurations.filter((value) => Number.isFinite(value));
  let tookMs: number | undefined;
  if (totalDurations.length > 0) {
    tookMs = aggregateTotalDurations(totalDurations, options.totalDurationAggregator);
  }

  if (!Number.isFinite(tookMs ?? Number.NaN)) {
    const fallback = stageMaxima.length > 0 ? Math.max(...stageMaxima) : undefined;
    if (fallback !== undefined && Number.isFinite(fallback)) {
      tookMs = fallback;
      notes.push("tookMs calculé à partir des maxima de phase faute de mesure explicite.");
    } else {
      tookMs = 0;
      notes.push("Aucune durée totale exploitable n'a été trouvée pour le scénario.");
    }
  }

  const documentIds = new Set(samples.documentIds);
  const incrementTotal = samples.documentCountIncrements
    .filter((value) => Number.isFinite(value))
    .reduce((acc, value) => acc + value, 0);
  const documentsIngested = Math.max(documentIds.size, Math.trunc(incrementTotal));

  const errorCounts: Record<string, number> = {};
  for (const category of samples.errorCategories) {
    errorCounts[category] = (errorCounts[category] ?? 0) + 1;
  }

  const report: ScenarioTimingReport = {
    searxQuery: timings.searxQuery ?? emptyBucket(),
    fetchUrl: timings.fetchUrl ?? emptyBucket(),
    extractWithUnstructured: timings.extractWithUnstructured ?? emptyBucket(),
    ingestToGraph: timings.ingestToGraph ?? emptyBucket(),
    ingestToVector: timings.ingestToVector ?? emptyBucket(),
    tookMs: tookMs ?? 0,
    documentsIngested,
    errors: errorCounts,
  };

  return { report, notes };
}

/**
 * Extracts raw metric samples from a list of JSON events. The function tolerates
 * heterogeneous payloads and records diagnostics when encountering malformed
 * data.
 */
export function extractScenarioMetricsFromEvents(
  events: readonly Record<string, unknown>[],
  options: ExtractScenarioMetricsOptions = {},
): { readonly samples: ScenarioMetricSamples; readonly notes: readonly string[] } {
  const stageDurations: Partial<Record<ScenarioTimingStage, number[]>> = {};
  const totalDurations: number[] = [];
  const documentIds = new Set<string>();
  const documentCountIncrements: number[] = [];
  const errorCategories: string[] = [];
  const notes: string[] = [];

  const stageLookup = buildStageLookup(options.stageMap);

  const stageExtractor =
    options.stageExtractor ??
    ([
      ["stage"],
      ["metrics", "stage"],
      ["timing", "stage"],
      ["payload", "stage"],
    ] as const);
  const durationExtractor = options.durationExtractor ?? ([
    ["durationMs"],
    ["duration_ms"],
    ["metrics", "durationMs"],
    ["metrics", "duration_ms"],
  ] as const);
  const totalDurationExtractor = options.totalDurationExtractor ?? ([
    ["tookMs"],
    ["metrics", "tookMs"],
    ["timing", "tookMs"],
    ["durationMsTotal"],
  ] as const);
  const documentIdExtractor = options.documentIdExtractor ?? ([
    ["documentId"],
    ["docId"],
    ["payload", "documentId"],
  ] as const);
  const documentCountExtractor = options.documentCountExtractor ?? ([
    ["documentsIngested"],
    ["payload", "documentsIngested"],
  ] as const);
  const documentSuccessExtractor = options.documentSuccessExtractor ?? ([
    ["success"],
    ["status"],
  ] as const);
  const documentSuccessValues = options.documentSuccessValues ?? [true, "success"];
  const errorCategoryExtractor = options.errorCategoryExtractor ?? ([
    ["category"],
    ["error", "category"],
    ["payload", "category"],
  ] as const);

  for (const [index, event] of events.entries()) {
    const stage = resolveStage(extractString(event, stageExtractor), stageLookup);
    if (stage) {
      const duration = extractNumber(event, durationExtractor);
      if (typeof duration === "number" && Number.isFinite(duration)) {
        const container = stageDurations[stage] ?? (stageDurations[stage] = []);
        container.push(duration);
      } else if (duration !== undefined) {
        notes.push(
          `L'événement #${index + 1} contient une durée invalide pour la phase ${stage}.`,
        );
      }
    }

    const totalDuration = extractNumber(event, totalDurationExtractor);
    if (typeof totalDuration === "number" && Number.isFinite(totalDuration)) {
      totalDurations.push(totalDuration);
    } else if (totalDuration !== undefined) {
      notes.push(`L'événement #${index + 1} expose une durée totale invalide.`);
    }

    const documentId = extractString(event, documentIdExtractor);
    const documentSuccess = extractValue(event, documentSuccessExtractor);
    if (documentId && isSuccessful(documentSuccess, documentSuccessValues)) {
      documentIds.add(documentId);
    }

    const documentCount = extractNumber(event, documentCountExtractor);
    if (typeof documentCount === "number" && Number.isFinite(documentCount)) {
      documentCountIncrements.push(documentCount);
    } else if (documentCount !== undefined) {
      notes.push(`L'événement #${index + 1} porte un compteur de documents invalide.`);
    }

    const errorCategory = extractString(event, errorCategoryExtractor);
    if (errorCategory) {
      errorCategories.push(errorCategory);
    }
  }

  const samples: ScenarioMetricSamples = {
    stageDurations,
    totalDurations,
    documentIds: [...documentIds],
    documentCountIncrements,
    errorCategories,
  };

  return { samples, notes };
}

/**
 * Convenience helper computing the full timing report from raw events. Notes
 * produced during extraction and aggregation are concatenated to provide
 * immediate guidance to the caller.
 */
export function computeScenarioTimingReportFromEvents(
  events: readonly Record<string, unknown>[],
  options: ComputeScenarioMetricsOptions = {},
): { readonly report: ScenarioTimingReport; readonly notes: readonly string[] } {
  const extraction = extractScenarioMetricsFromEvents(events, options);
  const aggregation = buildScenarioTimingReport(extraction.samples, options);
  return {
    report: aggregation.report,
    notes: [...extraction.notes, ...aggregation.notes],
  };
}

/**
 * Reads an NDJSON file and computes the corresponding timing report. Parsing
 * errors are reported through the diagnostic notes so operators can fix the
 * artefacts before re-running the command.
 */
export async function computeScenarioTimingReportFromFile(
  eventsPath: string,
  options: ComputeScenarioMetricsOptions = {},
): Promise<{ readonly report: ScenarioTimingReport; readonly notes: readonly string[] }> {
  const parseResult = await parseNdjsonFile(eventsPath);
  const computation = computeScenarioTimingReportFromEvents(parseResult.events, options);
  return {
    report: computation.report,
    notes: [...parseResult.notes, ...computation.notes],
  };
}

/**
 * Aggregated representation of a scenario used to populate dashboard widgets.
 * The structure mirrors the core metrics requested by the checklist while
 * adding contextual metadata (slug, libellé, horodatage de génération).
 */
export interface ScenarioDashboardExport {
  /** Numeric identifier of the scenario (S01 → 1, ...). */
  readonly scenarioId: number;
  /** Canonical slug used to name folders and artefacts. */
  readonly slug: string;
  /** Human readable label displayed in documentation/reporting. */
  readonly label: string;
  /** ISO timestamp describing when the export was generated. */
  readonly generatedAt: string;
  /** Total runtime observed for the scenario. */
  readonly tookMs: number;
  /** Number of successfully ingested documents. */
  readonly documentsIngested: number;
  /** Error counters grouped by taxonomy category. */
  readonly errors: Record<string, number>;
  /** Timing buckets grouped by canonical stage. */
  readonly stages: Record<ScenarioTimingStage, ScenarioTimingBucket>;
}

/** Options accepted while materialising dashboard exports on disk. */
export interface WriteScenarioDashboardOptions {
  /** Optional layout override to reuse filesystem resolutions. */
  readonly layout?: ValidationRunLayout;
  /** Base root forwarded to {@link ensureValidationRunLayout} when needed. */
  readonly baseRoot?: string;
  /** Custom timestamp propagated to the `generatedAt` field. */
  readonly now?: Date;
}

/** Result returned when persisting a dashboard export. */
export interface ScenarioDashboardWriteResult {
  /** Canonical payload written to disk. */
  readonly export: ScenarioDashboardExport;
  /** Absolute file path of the generated JSON artefact. */
  readonly path: string;
}

/**
 * Builds the JSON payload describing a scenario dashboard export. Keeping the
 * helper isolated makes it straightforward to reuse inside tests or future
 * renderers without hitting the filesystem.
 */
export function buildScenarioDashboardExport(
  scenarioId: number,
  scenarioSlug: string,
  scenarioLabel: string,
  report: ScenarioTimingReport,
  generatedAt: Date = new Date(),
): ScenarioDashboardExport {
  const stages: Record<ScenarioTimingStage, ScenarioTimingBucket> = {
    searxQuery: { ...report.searxQuery },
    fetchUrl: { ...report.fetchUrl },
    extractWithUnstructured: { ...report.extractWithUnstructured },
    ingestToGraph: { ...report.ingestToGraph },
    ingestToVector: { ...report.ingestToVector },
  };

  return {
    scenarioId,
    slug: scenarioSlug,
    label: scenarioLabel,
    generatedAt: generatedAt.toISOString(),
    tookMs: report.tookMs,
    documentsIngested: report.documentsIngested,
    errors: { ...report.errors },
    stages,
  };
}

/**
 * Writes the dashboard export matching the provided scenario to
 * `validation_run/metrics/<slug>_dashboard.json`.
 */
export async function writeScenarioDashboardExport(
  scenarioId: number,
  report: ScenarioTimingReport,
  options: WriteScenarioDashboardOptions = {},
): Promise<ScenarioDashboardWriteResult> {
  const layout = options.layout ?? (await ensureValidationRunLayout(options.baseRoot));
  const scenario = resolveScenarioById(scenarioId);
  const slug = formatScenarioSlug(scenario);
  const payload = buildScenarioDashboardExport(
    scenario.id,
    slug,
    scenario.label,
    report,
    options.now ?? new Date(),
  );

  const targetPath = path.join(layout.metricsDir, `${slug}_dashboard.json`);
  await writeFile(targetPath, `${JSON.stringify(payload, null, 2)}\n`, "utf8");

  return { export: payload, path: targetPath };
}

/** Parses an NDJSON file into JSON records while collecting diagnostics. */
async function parseNdjsonFile(
  eventsPath: string,
): Promise<{ readonly events: Record<string, unknown>[]; readonly notes: readonly string[] }> {
  const notes: string[] = [];
  let content: string;
  try {
    content = await readFile(eventsPath, "utf8");
  } catch (error) {
    throw new Error(`Impossible de lire ${eventsPath}: ${(error as Error).message}`);
  }

  const events: Record<string, unknown>[] = [];
  const lines = content.split(/\r?\n/);
  for (const [index, line] of lines.entries()) {
    const trimmed = line.trim();
    if (trimmed.length === 0) {
      continue;
    }
    try {
      const parsed = JSON.parse(trimmed);
      if (parsed && typeof parsed === "object") {
        events.push(parsed as Record<string, unknown>);
      } else {
        notes.push(`Ligne ${index + 1}: le contenu JSON n'est pas un objet.`);
      }
    } catch (error) {
      notes.push(`Ligne ${index + 1}: JSON invalide (${(error as Error).message}).`);
    }
  }

  return { events, notes };
}

/** Computes the requested percentile using linear interpolation. */
function computePercentile(sorted: readonly number[], percentile: number): number {
  if (sorted.length === 1) {
    return sorted[0];
  }

  const position = ((percentile / 100) * (sorted.length - 1));
  const lowerIndex = Math.floor(position);
  const upperIndex = Math.ceil(position);
  const lowerValue = sorted[lowerIndex];
  const upperValue = sorted[upperIndex];

  if (upperIndex === lowerIndex) {
    return lowerValue;
  }

  const weight = position - lowerIndex;
  return lowerValue + (upperValue - lowerValue) * weight;
}

/** Aggregates scenario runtimes using the requested strategy. */
function aggregateTotalDurations(
  durations: readonly number[],
  strategy: BuildScenarioTimingReportOptions["totalDurationAggregator"],
): number {
  const sorted = [...durations].sort((a, b) => a - b);
  if (typeof strategy === "function") {
    return strategy(sorted);
  }

  switch (strategy) {
    case "median":
      return computePercentile(sorted, 50);
    case "p95":
      return computePercentile(sorted, 95);
    case "max":
    case undefined:
      return sorted[sorted.length - 1];
    default:
      return sorted[sorted.length - 1];
  }
}

/** Returns an empty timing bucket used as a placeholder when samples are missing. */
function emptyBucket(): ScenarioTimingBucket {
  return { p50: 0, p95: 0, p99: 0 };
}

/** Normalises and resolves a stage identifier against the canonical lookup. */
function resolveStage(
  value: string | undefined,
  lookup: ReadonlyMap<string, ScenarioTimingStage>,
): ScenarioTimingStage | undefined {
  if (!value) {
    return undefined;
  }
  const normalised = normaliseKey(value);
  return lookup.get(normalised);
}

/** Builds the lookup map combining canonical stages and custom overrides. */
function buildStageLookup(
  overrides: Readonly<Record<string, ScenarioTimingStage>> | undefined,
): ReadonlyMap<string, ScenarioTimingStage> {
  const entries: [string, ScenarioTimingStage][] = [];
  for (const stage of SCENARIO_TIMING_STAGES) {
    entries.push([normaliseKey(stage), stage]);
  }
  if (overrides) {
    for (const [raw, stage] of Object.entries(overrides)) {
      entries.push([normaliseKey(raw), stage]);
    }
  }
  return new Map(entries);
}

/** Extracts a string from the record using the configured extractor. */
function extractString(record: Record<string, unknown>, extractor: ValueExtractor): string | undefined {
  const value = extractValue(record, extractor);
  if (typeof value === "string") {
    const trimmed = value.trim();
    return trimmed.length > 0 ? trimmed : undefined;
  }
  return undefined;
}

/** Extracts a numeric value, accepting numeric strings. */
function extractNumber(record: Record<string, unknown>, extractor: ValueExtractor): number | undefined {
  const value = extractValue(record, extractor);
  if (typeof value === "number") {
    return Number.isFinite(value) ? value : undefined;
  }
  if (typeof value === "string") {
    const parsed = Number.parseFloat(value);
    return Number.isFinite(parsed) ? parsed : undefined;
  }
  return undefined;
}

/** Generic extraction helper supporting nested paths and fallback descriptors. */
function extractValue(record: Record<string, unknown>, extractor: ValueExtractor): unknown {
  if (typeof extractor === "function") {
    return extractor(record);
  }
  if (!Array.isArray(extractor)) {
    return undefined;
  }

  if (extractor.length === 0) {
    return undefined;
  }

  const first = extractor[0];
  if (typeof first === "string" || typeof first === "number") {
    return getPath(record, extractor as readonly (string | number)[]);
  }

  for (const candidate of extractor as readonly ScalarExtractor[]) {
    const value = extractValue(record, candidate);
    if (value !== undefined) {
      return value;
    }
  }
  return undefined;
}

/** Retrieves a nested property from the record following the provided path. */
function getPath(record: unknown, path: readonly (string | number)[]): unknown {
  let current: unknown = record;
  for (const segment of path) {
    if (
      current === null ||
      typeof current !== "object" ||
      !Object.hasOwn(current as Record<string, unknown>, segment as keyof typeof current)
    ) {
      return undefined;
    }
    current = (current as Record<string, unknown>)[segment as keyof typeof current];
  }
  return current;
}

/** Determines whether the ingestion event should be counted as successful. */
function isSuccessful(value: unknown, accepted: readonly unknown[]): boolean {
  if (value === undefined) {
    return true;
  }
  if (typeof value === "boolean") {
    return value;
  }
  for (const candidate of accepted) {
    if (candidate === value) {
      return true;
    }
    if (typeof candidate === "string" && typeof value === "string") {
      if (candidate.toLowerCase() === value.toLowerCase()) {
        return true;
      }
    }
  }
  return false;
}

/** Normalises a string for lookup comparisons. */
function normaliseKey(value: string): string {
  return value
    .normalize("NFKD")
    .replace(/\p{Mark}+/gu, "")
    .replace(/[^\p{Letter}\p{Number}]+/gu, "_")
    .replace(/^_+|_+$/gu, "")
    .toLowerCase()
    .replace(/_/g, "");
}
